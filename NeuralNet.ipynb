{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Networks\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Neural_Network' object has no attribute 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 107>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=103'>104</a>\u001b[0m         \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mExpected (X1-X3): \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(xPredicted))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=104'>105</a>\u001b[0m         \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mOutput (Y1): \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeedForward(xPredicted)))\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=106'>107</a>\u001b[0m myNeuralNet \u001b[39m=\u001b[39m Neural_Network()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=107'>108</a>\u001b[0m trainingEpochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=108'>109</a>\u001b[0m \u001b[39m#trainingEpochs = 100000\u001b[39;00m\n",
      "\u001b[1;32m/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb Cell 1'\u001b[0m in \u001b[0;36mNeural_Network.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=28'>29</a>\u001b[0m     \u001b[39m# parameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=29'>30</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputLayerSize \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39m#X1, X2, X3\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=30'>31</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput\u001b[39m.\u001b[39mLayerSize \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m#Y1 \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=31'>32</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhiddenLayerSize \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m    \u001b[39m# size of hidden layers\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=34'>35</a>\u001b[0m     \u001b[39m# build weights of each layer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=35'>36</a>\u001b[0m     \u001b[39m# set to random values\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=36'>37</a>\u001b[0m     \u001b[39m# look at the interconnection diagram to make sense of this\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lanreborishade/VScode/Neural_Networks/Untitled-1.ipynb#ch0000000?line=37'>38</a>\u001b[0m     \u001b[39m# 3x4 matrix for input to hidden\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Neural_Network' object has no attribute 'output'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "print(\"Neural Networks\")\n",
    "\n",
    "# X = input of our 3 input XOR gate \n",
    "# setting up the inputs of the neural network (An XOR table with all the different inputs)\n",
    "\n",
    "X  = np.array(([0,0,0],[0,0,1],[0,1,0], \\\n",
    "              [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)\n",
    "\n",
    "# y = our output of our neural network\n",
    "y = np.array(([1], [0], [0], [0], [0], \\\n",
    "              [0], [0], [1]), dtype=float)\n",
    "\n",
    "\n",
    "# the value we want to predict\n",
    "xPredicted = np.array(([0,0,1]), dtype=float)\n",
    "X = X/np.amax(X, axis=0) # maximum of X input array\n",
    "\n",
    "# maximum of xPredicted (our input data for the prediction)\n",
    "xPredicted = xPredicted/np.amax(xPredicted, axis=0)\n",
    "\n",
    "# set up our Loss file for graphing\n",
    "lossFile = open(\"SumSquaredLossList.csv\", \"w\")\n",
    "\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        # parameters\n",
    "        self.inputLayerSize = 3 #X1, X2, X3\n",
    "        self.hiddenLayerSize = 4    # size of hidden layers\n",
    "        self.output.LayerSize = 1 #Y1 \n",
    "\n",
    "\n",
    "        # build weights of each layer\n",
    "        # set to random values\n",
    "        # look at the interconnection diagram to make sense of this\n",
    "        # 3x4 matrix for input to hidden\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
    "        # 4x1 matrix for hidden layer to output\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n",
    "\n",
    "    def feedForward(self, X):\n",
    "        # feedForward propagation through our network\n",
    "        # dot product of X (input) and first set of 3x4 weights\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        # the activationSigmoid activation function - neural magic\n",
    "        self.z2 = self.activationSigmoid(self.z)\n",
    "        # dot product of hidden layer (z2) and second set of 4x1 weights\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        # final activation function - more neural magic\n",
    "        o = self.activationSigmoid(self.z3)\n",
    "        return o\n",
    "\n",
    "\n",
    "    def backwardPropagate(self, X, y, o):\n",
    "        # backward propagate through the network \n",
    "        # calculate value of error in the output \n",
    "        self.o_error = y - o\n",
    "        # apply derivative of activationSigmoid to error\n",
    "        self.o_delta = self.o_error*self.activationSigmoidPrime(o)\n",
    "        # z2 error: how much our hidden layer weights contributed to output\n",
    "        # error\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T)\n",
    "        # applying derivative of activationSigmoid to z2 error\n",
    "        self.z2_delta = self.z2_error*self.activationSigmoidPrime(self.z2)\n",
    "        # adjusting first set (inputLayer --&gt; hiddenLayer) weights\n",
    "        self.W1 += X.T.dot(self.z2_delta)\n",
    "        # adjusting second set (hiddenLayer --&gt; outputLayer) weights\n",
    "        self.W2 += self.z2.T.dot(self.o_delta)\n",
    "\n",
    "\n",
    "    def trainNetwork(self, X, y):\n",
    "        # feed forward the loop \n",
    "        o = self.feedForward(X)\n",
    "\n",
    "        # and then back propagate the values \n",
    "        self.backwardPropagate(X, y, o)\n",
    "\n",
    "\n",
    "    def activationSigmoid(self, s):\n",
    "        # activation function\n",
    "        # simple activationSigmoid curve as in the book\n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "\n",
    "    def activationSigmoidPrime(self, s):\n",
    "        # First derivative of activationSigmoid\n",
    "        # calculus time!\n",
    "        return s * (1 - s)\n",
    "\n",
    "\n",
    "    def saveSumSquaredLossList(self,i,error):\n",
    "        lossFile.write(str(i)+\",\"+str(error.tolist())+'\\n')\n",
    "\n",
    "\n",
    "    def saveWeights(self):\n",
    "        # save this in order to reproduce our cool network\n",
    "        np.savetxt(\"weightsLayer1.txt\", self.W1, fmt=\"%s\")\n",
    "        np.savetxt(\"weightsLayer2.txt\", self.W2, fmt=\"%s\")\n",
    "\n",
    "    def predictOutput(self):\n",
    "        print (\"Predicted XOR output data based on trained weights: \")\n",
    "        print (\"Expected (X1-X3): \\n\" + str(xPredicted))\n",
    "        print (\"Output (Y1): \\n\" + str(self.feedForward(xPredicted)))\n",
    "\n",
    "\n",
    "myNeuralNet = Neural_Network()\n",
    "trainingEpochs = 1000 \n",
    "#trainingEpochs = 100000\n",
    "\n",
    "\n",
    "for i in range(trainingEpochs):\n",
    "    print(\"Epoch # \" + str(i) + \"\\n\")\n",
    "    print(\"Network Input : \\n\" + str(X))\n",
    "    print(\"Expected Output of XOR Gate Neural Network: \\n\" + str(y))\n",
    "    print(\"Actual Output from XOR Gate Neural Network: \\n\" +  str(myNeuralNet.feedForward(X)))\n",
    "    \n",
    "    # mean sum squared loss\n",
    "    Loss = np.mean(np.square(y - myNeuralNet.feedForward(X)))\n",
    "    myNeuralNet.saveSumSquaredLossList(i,Loss)\n",
    "    print (\"Sum Squared Loss: \\n\" + str(Loss))\n",
    "    print (\"\\n\")\n",
    "    myNeuralNet.trainNetwork(X, y)\n",
    "\n",
    "myNeuralNet.saveWeights()\n",
    "myNeuralNet.predictOutput()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
